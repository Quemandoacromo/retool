from __future__ import annotations

import html
import os
import pathlib
import re
import sys
from contextlib import nullcontext
from functools import partial
from typing import TYPE_CHECKING, Any

import psutil
from alive_progress import alive_bar  # type: ignore
from lxml import etree
from lxml import html as html_

import modules.constants as const

if TYPE_CHECKING:
    from modules.config import Config
    from modules.input import UserInput

from modules.clone_list import CloneList
from modules.interruptible_pool import InterruptiblePool
from modules.titletools import Regex, TitleTools
from modules.utils import ExitRetool, Font, eprint, format_value, pattern2string, regex_test


class Dat:
    def __init__(
        self,
        contents: list[str] = [],
        header: list[str] = [],
        name: str = 'Unknown',
        description: str = 'Unknown',
        version: str = 'Unknown',
        author: str = 'Unknown',
        homepage: str = 'Unknown',
        url: str = 'Unknown',
        comment: str = 'Unknown',
        numbered: bool = False,
        clone_list: CloneList = CloneList(),
        metadata: dict[str, dict[str, str]] = {},
        end: bool = False,
        output_filename: str = '',
    ) -> None:
        """
        Creates an object that contains an input DAT's details. Interactively
        browsable if you `print()` the object.

        Args:
            contents (list[str], optional): Stores the contents of a DAT in a
            line-by-line fashion. Defaults to `[]`.

            header (list[str], optional): The original DAT header. Defaults to `[]`.

            name (str, optional): The name in the DAT header. Defaults to `Unknown`.

            description (str, optional): The description in the DAT header. Defaults to
            `Unknown`.

            version (str, optional): The version in the DAT header. Defaults to
            `Unknown`.

            author (str, optional): The author in the DAT header. Defaults to
            `Unknown`.

            homepage (str, optional): The homepage in the DAT header. Defaults to
            `Unknown`.

            url (str, optional): The URL in the DAT header. Defaults to `Unknown`.

            comment (str, optional): The comment in the DAT header. Defaults to
            `Unknown`.

            numbered (bool, optional): Whether the DAT's titles are prefixed with a
            number. Defaults to `False`.

            clone_list (CloneList, optional): A CloneList object built from a clone list
            related to the DAT. Defaults to `CloneList():.

            metadata (dict[str, dict[str, str]], optional): Metadata related to the DAT,
            that contains languages for each of the titles scraped from No-Intro and
            Redump's sites. Defaults to `{}`.

            end (bool, optional): If something goes wrong during batch processing,
            Retool sets this to `True`, which allows it to move onto the next file in
            the batch. Defaults to `False`.

            output_filename (str, optional): Stores the name of the output file
            generated by Retool. Defaults to `''`.
        """
        self.name: str = name
        self.original_header: list[str] = header
        self.output_filename: str = output_filename
        self.description: str = description
        self.version: str = version
        self.author: str = author
        self.homepage: str = homepage
        self.url: str = url
        self.comment: str = comment
        self.dat_manager_directives: list[str] = []
        self.is_dtd = False
        self.datafile_tag = ''
        self.numbered: bool = numbered
        self.contents: list[str] = contents
        self.contents_str: str = ''.join(contents)
        self.contents_dict: dict[str, set[DatNode]] = {}
        self.clone_list: CloneList = clone_list
        self.metadata: dict[str, dict[str, str]] = metadata
        self.search_name: str = ''
        self.retool: str = ''
        self.end: bool = end

    def __str__(self) -> str:
        return_attributes: list[list[str]] = []

        for attribute in dir(self):
            if not attribute.startswith('__'):
                if len(str(getattr(self, attribute))) > 80:
                    return_attributes.append(
                        [
                            f'  ├ .{attribute}:',
                            f'(...) {format_value(str(type(getattr(self, attribute)).__name__))}',
                        ]
                    )
                else:
                    return_attributes.append(
                        [f'  ├ .{attribute}:', format_value(getattr(self, attribute))]
                    )

        final_item: list[str] = return_attributes[-1].copy()

        for i, s in enumerate(final_item):
            return_attributes[-1][i] = s.replace('├', '└')

        # Column alignment
        def class_output() -> None:
            eprint('\n  ○ Dat object')
            col_width: int = max(len(word) for row in return_attributes for word in row) - 20
            for row in return_attributes:
                eprint(''.join(str(word).ljust(col_width) for word in row), wrap=False)

        key: str = 'blank'

        class_output()

        while key != 'q':
            eprint(
                '\nEnter a dictionary key to expand (e.g. tags_disc_rename), q to continue, or hit enter to list: '
            )
            key = input()

            eprint(key)

            if hasattr(self, key):
                if isinstance(getattr(self, key), CloneList | Regex):
                    eprint(f'\n{vars(getattr(self, key))}', wrap=False)
                else:
                    eprint(f'\n{format_value(getattr(self, key))}', wrap=False)
            elif key == '':
                class_output()
            else:
                if key != 'q':
                    eprint(f'\nUnknown key "{key}".', wrap=False)
                else:
                    break

        return ''


class DatNode:
    def __init__(self, config: Config, input_dat: Dat, node: dict[str, Any]) -> None:
        """
        Creates an object that contains all of a title's properties. If you
        `print()` a DatNode object, it shows you a tree-like view of all its
        contents.

        Args:
            config (Config): The Retool config object.

            input_dat (Dat): The Retool input_dat object.

            node (dict[str, Any]): A dict created from a title's XML element
            in the DAT, containing information like name, category, description
            and ROMs if present.
        """
        # Set the XML element name
        self.element_name: str = node['element_name']

        # Set full/numbered names
        self.full_name: str = ''
        self.full_name_original: str = ''
        self.numbered_name: str = ''
        self.local_name: str = ''

        if not input_dat.numbered:
            self.full_name = node['name']
        else:
            self.full_name = node['name'][7:]
            self.numbered_name = node['name']

        self.full_name = TitleTools.replace_invalid_characters(
            self.full_name, config, is_header_detail=False
        )
        self.full_name_original = self.full_name

        # Get the tags
        self.tags: set[str] = set([f'({x}' for x in self.full_name.split(' (')][1:None])

        # Set languages and regions
        self.languages_implied: tuple[str, ...] = ()
        self.languages_online: tuple[str, ...] = ()
        self.languages_title: tuple[str, ...] = ()
        self.languages: tuple[str, ...] = ()
        self.languages_original: tuple[str, ...] = ()
        self.regions: tuple[str, ...] = ()
        self.primary_region: str = ''
        self.primary_region_original: str = ''
        self.secondary_region: str = ''

        if self.full_name in input_dat.metadata:
            if not input_dat.metadata[self.full_name]['languages']:
                self.languages_online = ()
            else:
                self.languages_online = tuple(
                    sorted(input_dat.metadata[self.full_name]['languages'])
                )

        self.languages_title_str: str = TitleTools.languages(
            self.full_name, self.tags, config, 'get'
        )
        self.languages_title_orig_str: str = self.languages_title_str

        if '+' in self.languages_title_str:
            self.languages_title_str = self.languages_title_str.replace('+', ',')

        if self.languages_title_str:
            self.languages_title = tuple(sorted(set(self.languages_title_str.split(','))))

        self.regions_str: str = TitleTools.regions(self.full_name, config, 'get')

        regions: list[str] = list(config.region_order_default)

        self.regions = tuple([region for region in regions if region in self.regions_str])

        if not self.regions:
            self.regions = ('Unknown',)

        self.primary_region = self.regions[0]
        self.primary_region_original = self.primary_region

        # Get the primary region based on the region order
        region_order: list[str] = config.region_order_user

        if config.system_region_order_user:
            if {'override': 'true'} in config.system_region_order_user:
                region_order = [
                    str(x) for x in config.system_region_order_user if 'override' not in x
                ]

        if len(self.regions) > 1:
            for region in region_order:
                if region in self.regions:
                    self.primary_region = region
                    break

        if not self.primary_region:
            self.primary_region = self.regions[0]

        if len(self.regions) > 1:
            self.secondary_region = [x for x in self.regions if x not in [self.primary_region]][0]

        if self.primary_region in config.languages_implied:
            self.languages_implied = config.languages_implied[self.primary_region]

        # Set the canonical supported languages for the title
        if self.languages_online:
            if self.languages_online != ('nolang',):
                self.languages = self.languages_online
            else:
                self.languages_online = ()

        if not self.languages_online and not self.languages_title:
            self.languages = self.languages_implied

        if not self.languages_online and self.languages_title:
            self.languages = self.languages_title

        self.languages_original = self.languages

        # If the language code for the title is just Zh, try to infer whether simplified
        # or traditional Chinese is being used
        if 'Zh' in self.languages:
            if 'China' in self.regions or 'Singapore' in self.regions:
                self.languages = tuple([x.replace('Zh', 'Zh-Hans') for x in self.languages])
            elif 'Hong Kong' in self.regions or 'Taiwan' in self.regions:
                self.languages = tuple([x.replace('Zh', 'Zh-Hant') for x in self.languages])

        # Set various names used for title matching -- for speed, we don't use all of the
        # built-in name conversion functions, as they generate the names from scratch which
        # requires extra work
        regions_replace: str = f' ({self.regions_str})'
        languages_replace: str = f' ({self.languages_title_orig_str})'

        self.short_name: str = TitleTools.get_short_name(self.full_name, self.tags, config)
        self.region_free_name: str = self.full_name.replace(languages_replace, '').replace(
            regions_replace, ''
        )
        self.short_name_original: str = self.short_name
        self.group_name: str = TitleTools.get_group_name(self.full_name, config)
        self.group_name_conditional: str = ''

        # Set an indicator if the title has been moved using a clone list condition
        self.group_moved_by_condition: bool = False

        # Pull local names from metadata
        metadata_local_language: str = ''

        if self.full_name in input_dat.metadata:
            if 'localName' in input_dat.metadata[self.full_name]:

                # Check if a system config is in play
                local_name_user_order_language_codes: list[str] = []

                if config.system_localization_order_user:
                    if {'override': 'true'} in config.system_localization_order_user:
                        local_name_user_order_language_codes = [
                            str(x)
                            for x in config.system_localization_order_user
                            if 'override' not in x
                        ]
                elif config.localization_order_user:
                    local_name_user_order_language_codes = list(config.localization_order_user)

                # Get the inferred language from the primary region
                if self.primary_region in config.languages_filter:
                    if config.languages_filter[self.primary_region]:
                        metadata_local_language = config.languages_filter[self.primary_region][0]

                # Make sure the alternate name is only applied if the title only has one or
                # two languages, and don't change the title if the only language is English
                if len(self.languages) <= 2 and self.languages != ('En',):
                    if metadata_local_language in local_name_user_order_language_codes:
                        self.local_name = input_dat.metadata[self.full_name]['localName']

        # Re-add the tags to the local name where appropriate
        if self.local_name:
            tags = pattern2string(re.compile(' \\(.*'), self.full_name)
            self.local_name = f'{self.local_name}{tags}'

        # Populate the description and rom fields
        if 'description' in node:
            self.description: str = node['description']

        if 'roms' in node:
            self.roms: list[dict[str, str]] = node['roms']

        def rom_format(attribute: str) -> None:
            """
            Checks that the various ROM attributes are available, and formats
            them accordingly.

            Args:
                attribute (str): The attribute to format, either `crc`, `md5`,
                `sha1`, `sha256`, or `header`.
            """
            for rom in self.roms:
                if attribute not in rom:
                    rom[attribute] = ''

                if (
                    attribute == 'crc'
                    or attribute == 'md5'
                    or attribute == 'sha1'
                    or attribute == 'sha256'
                    or attribute == 'header'
                ):
                    rom[attribute] = rom[attribute].lower()

        rom_attributes: list[str] = [
            'name',
            'crc',
            'header',
            'mia',
            'md5',
            'sha1',
            'sha256',
            'size',
        ]

        for attribute in rom_attributes:
            rom_format(attribute)

        self.cloneof: str = ''
        self.clonelist_priority: int = 1
        self.is_superset: bool = False
        self.is_mia: bool = False
        self.contains_titles: dict[str, dict[str, int]] = {}

        # Determine if a title is fully MIA
        if '[MIA]' in self.full_name:
            self.is_mia = True

            for rom in self.roms:
                rom['mia'] = 'yes'

        if len([x for x in self.roms if x['mia'] == 'yes']) == len(self.roms):
            self.is_mia = True

        # Work with categories
        self.categories: list[str] = []

        if 'category' in node:
            for category in node['category']:
                if node['category'] == 'Console':
                    self.categories.append('BIOS')
                else:
                    self.categories.append(category)

        def category_assign(regexes: tuple[Any, ...], category: str) -> None:
            """
            Assigns a category to a title based on a regex match in its name.

            Args:
                regexes (tuple[Any, ...]): A collection of regexes to
                iterate through.

                category (str): The category to assign to the title if a
                regex matches.
            """
            for item in regexes:
                if re.search(item, self.full_name):
                    if category not in self.categories:
                        self.categories.append(category)

        category_assign((config.regex.programs,), 'Applications')
        category_assign((config.regex.bios,), 'BIOS')
        category_assign(config.regex.demos, 'Demos')
        category_assign((config.regex.multimedia,), 'Multimedia')
        category_assign(config.regex.preproduction, 'Preproduction')
        category_assign(config.regex.video, 'Video')

        if '[bios]' in self.full_name.lower():
            if 'BIOS' not in self.categories:
                self.categories.append('BIOS')
        elif self.categories == []:
            self.categories.append('Games')

        # Check if there's no (Demo) or related tags for titles with the category "Demos",
        # and add it if so
        is_demo: bool = False

        for demo_regex in config.regex.demos:
            if re.search(demo_regex, self.full_name):
                is_demo = True

        if not is_demo and 'Demos' in self.categories:
            self.short_name = f'{self.short_name.strip()} (Demo)'
            self.region_free_name = f'{self.region_free_name.strip()} (Demo)'

        self.short_name = self.short_name.lower()

        # Add a reason why a title was excluded/included, and if its related titles should
        # also be excluded/included by Retool
        self.exclude_reason: str = ''
        self.include_reason: str = ''
        self.exclude_include_related: bool = False

        # Assign user language and region priority
        region_priority: set[int] = set()
        language_priority: set[int] = set()

        # Check if a system config is in play
        language_order: list[str] = []

        if config.languages_filter:
            language_order = config.language_order_user

            if config.system_language_order_user:
                if {'override': 'true'} in config.system_language_order_user:
                    language_order = [
                        str(x) for x in config.system_language_order_user if 'override' not in x
                    ]
        else:
            language_order = config.region_order_languages_user

        for i, region in enumerate(region_order):
            if region in self.regions:
                region_priority.add(i)

                for j, language_code in enumerate(language_order):
                    for language in self.languages:
                        if re.search(language_code, language):
                            language_priority.add(j)

        if not region_priority:
            region_priority.add(100)

        if not language_priority:
            language_priority.add(100)

        self.region_priority: int = sorted(region_priority)[0]
        self.language_priority: int = sorted(language_priority)[0]

    def __str__(self) -> str:
        return_list: list[str] = []

        def format_attribute(attribute: Any, string: str, tabs: str, is_rom: bool = False) -> str:
            """
            Formats an output string based on whether an attribute in the object has a
            value or not, or if its value contains ROMs.

            Args:
                attribute (Any): The DatNode attribute.

                string (str): The name of the attribute to use in the output string.

                tabs (str): Tab indentation for the output string.

                is_rom (bool, optional): Whether or not the output string should be
                formatted for ROM data. Defaults to `False`.

            Returns:
                str: A formatted output string based on whether an attribute has a value
                or not, or if its value contains ROMs.
            """
            none_str: str = f'{Font.disabled}None{Font.end}'
            attribute_result: str = ''

            if not attribute:
                if not isinstance(attribute, int | bool):
                    attribute = none_str

            if is_rom:
                attribute_result = f'{string}: {attribute}'
            else:
                attribute_result = f'  ├ {string}:{tabs}{attribute}\n'

            return attribute_result

        return_list.append(f'  ○ full_name:\t\t\t{self.full_name}\n')
        return_list.append(format_attribute(self.numbered_name, 'numbered_name', '\t\t'))
        return_list.append(format_attribute(self.local_name, 'local_name', '\t\t\t'))
        return_list.append(f'  ├ description:\t\t{self.description}\n')
        return_list.append(f'  ├ region_free_name:\t\t{self.region_free_name}\n')
        return_list.append(f'  ├ short_name:\t\t\t{self.short_name}\n')
        return_list.append(f'  ├ group_name:\t\t\t{self.group_name}\n')
        return_list.append(f'  ├ group_moved_by_condition:\t{self.group_moved_by_condition}\n')
        return_list.append(format_attribute(self.tags, 'tags', '\t\t\t'))
        return_list.append(f'  ├ regions:\t\t\t{self.regions}\n')
        return_list.append(f'  ├ primary_region:\t\t{self.primary_region}\n')
        return_list.append(format_attribute(self.secondary_region, 'secondary_region', '\t\t'))
        return_list.append(
            format_attribute(self.languages_title_orig_str, 'languages_title_orig_str', '\t')
        )
        return_list.append(format_attribute(self.languages_title, 'languages_title', '\t\t'))
        return_list.append(format_attribute(self.languages_implied, 'languages_implied', '\t\t'))
        return_list.append(format_attribute(self.languages_online, 'languages_online', '\t\t'))
        return_list.append(format_attribute(self.languages, 'languages', '\t\t\t'))
        return_list.append(format_attribute(self.cloneof, 'cloneof', '\t\t\t'))
        return_list.append(format_attribute(self.is_superset, 'is_superset', '\t\t'))
        return_list.append(format_attribute(self.contains_titles, 'contains_titles', '\t\t'))
        return_list.append(format_attribute(self.clonelist_priority, 'clonelist_priority', '\t\t'))
        return_list.append(format_attribute(self.region_priority, 'region_priority', '\t\t'))
        return_list.append(format_attribute(self.language_priority, 'language_priority', '\t\t'))
        return_list.append(format_attribute(self.exclude_reason, 'exclude_reason', '\t\t'))
        return_list.append(format_attribute(self.include_reason, 'include_reason', '\t\t'))
        return_list.append(
            format_attribute(self.exclude_include_related, 'exclude_include_related', '\t')
        )
        return_list.append(f'  ├ categories:\t\t\t{self.categories}\n')
        return_list.append('  └ roms ┐ \n')
        for i, rom in enumerate(self.roms):
            if i == len(self.roms) - 1:
                return_list.append(
                    f'         └ name: {rom["name"]} | {format_attribute(rom["header"], "header", "", is_rom=True)} | {format_attribute(rom["mia"], "mia", "", is_rom=True)} | crc: {rom["crc"]} | md5: {rom["md5"]} | sha1: {rom["sha1"]} | {format_attribute(rom["sha256"], "sha256", "", is_rom=True)} | size: {rom["size"]}\n\n'
                )
            else:
                return_list.append(
                    f'         ├ name: {rom["name"]} | {format_attribute(rom["header"], "header", "", is_rom=True)} | {format_attribute(rom["mia"], "mia", "", is_rom=True)} | crc: {rom["crc"]} | md5: {rom["md5"]} | sha1: {rom["sha1"]} | {format_attribute(rom["sha256"], "sha256", "", is_rom=True)} | size: {rom["size"]}\n'
                )

        return_str: str = ''.join(return_list)

        return return_str


def convert_clrmame_dat(
    input_dat: Dat, input_type: str, gui_input: UserInput | None, config: Config
) -> Dat:
    """
    Converts a DAT file in CLRMAMEPro format to LogiqX DAT format.

    Args:
        input_dat (Dat): The Retool input_dat object.

        input_type (str): Whether Retool is operating on a file or folder.

        gui_input (UserInput): Used to determine whether or not the function is being
        called from the GUI.

        config (Config): The Retool config object.

    Raises:
        ExitRetool: Silently exit if run from the GUI, so UI elements can
        re-enable.

    Returns:
        Dat: A Dat object that looks as if it was created from a LogiqX-based
        DAT file.
    """
    clrmame_header: Any = re.search('^clrmamepro \\($.*?^\\)$', input_dat.contents_str, re.M | re.S)

    if clrmame_header:
        clrmame_header = clrmame_header.group()

    clrmame_titles: list[str] = re.findall('game \\($.*?^\\)$', input_dat.contents_str, re.M | re.S)

    convert_dat: list[str] = [
        '<?xml version="1.0"?>',
        '<!DOCTYPE datafile PUBLIC "-//Logiqx//DTD ROM Management Datafile//EN" "https://raw.githubusercontent.com/unexpectedpanda/retool-clonelists-metadata/main/datafile.dtd">',
        '<datafile>',
        '<header>',
    ]

    dat_name: str = ''
    dat_description: str = ''
    dat_category: str = ''
    dat_version: str = ''
    dat_author: str = ''
    dat_url: str = ''

    if clrmame_titles:

        def get_detail(
            key: str,
            group: str,
            is_header_detail: bool = True,
            rom_attrs: bool = False,
            hash_length: int = 0,
        ) -> str:
            """
            Gets details from a CLRMAMEPro DAT.

            Args:
                key (str): The string to search for.

                group (str): What group of information in the DAT to search for the
                string in. Usually the header, the rom string, or the game node.

                is_header_detail (bool, optional): Whether or not the detail is in the
                header. Defaults to `True`.

                rom_attrs (bool, optional): Whether or not the detail we're searching
                for is ROM attributes. Defaults to `False`.

                hash_length (int, optional): When searching for a ROM hash, specify the
                length of the hash (CRC=8, MD5=32, SHA-1=40, SHA-256=64). Defaults to `0`.

            Returns:
                str: The detail searched for, in an appropriately formatted string.
            """
            regex_search: Any

            if rom_attrs:
                search_string = f'{key}\\s.*?\\s'
                regex_search = re.findall(search_string, group)
            else:
                search_string = f'{key}\\s.*'
                regex_search = re.search(search_string, group)

            detail: str = ''

            if regex_search:
                # Check if the string contains quotes, convert accordingly
                if rom_attrs:
                    for attr in regex_search:
                        verify_value: str = attr.replace(f'{key} ', '').strip()

                        if key == 'size':
                            try:
                                detail = str(int(verify_value))
                            except Exception:
                                continue
                        else:
                            if len(verify_value) == hash_length:
                                try:
                                    if int(verify_value, 16):
                                        detail = str(verify_value)
                                except Exception:
                                    continue
                else:
                    regex_search_str: str = regex_search.group().replace(f'{key} ', '')
                    if '"' in regex_search_str:
                        search_string = f'{search_string}\".*\"'
                        try:
                            detail = html.escape(
                                regex_search_str.replace('"', '').strip(), quote=False
                            )
                        except Exception:
                            eprint(
                                '• This title in the DAT is malformed and will be skipped:',
                                level='warning',
                            )
                            eprint(f'  {group}', level='warning', wrap=False)
                    else:
                        search_string = f'{search_string}?\\s'
                        detail = html.escape(regex_search_str.strip(), quote=False)

                    if not is_header_detail:
                        for character in config.sanitized_characters:
                            if character in detail:
                                detail = detail.replace(character, '-')

            else:
                detail = ''

            if detail != '' and is_header_detail:

                if key == 'homepage':
                    key = 'url'

                convert_dat.append(f'\t\t<{key}>{detail}</{key}>\n')

            return detail

        # Get all the DAT details
        dat_name = TitleTools.replace_invalid_characters(
            get_detail('name', clrmame_header), config, is_header_detail=True
        )
        dat_description = get_detail('description', clrmame_header)
        if not dat_description:
            convert_dat.append(f'\t\t<description>{dat_name}</description>\n')
        dat_category = get_detail('category', clrmame_header)
        dat_version = TitleTools.replace_invalid_characters(
            get_detail('version', clrmame_header), config, is_header_detail=True
        )
        if not dat_version:
            convert_dat.append('\t\t<version>Unknown</version>\n')
        dat_author = get_detail('author', clrmame_header)
        if not dat_author:
            convert_dat.append('\t\t<author>Unknown</author>\n')
        dat_url = get_detail('homepage', clrmame_header)
        convert_dat.append('\t</header>\n')

        # Generate the node for each title
        for title in clrmame_titles:
            skip_node: bool = False

            clrmame_roms: list[str] = re.findall('rom\\s\\(.*?\\)$', title, re.M | re.S)
            rom_list: list[str] = []

            for rom in clrmame_roms:
                rom_string: str = rom.replace('(', '').replace(')', '')

                rom_size = get_detail('size', rom_string, is_header_detail=False, rom_attrs=True)
                rom_string = re.sub(f'size {rom_size}', '', rom_string)

                rom_crc = get_detail(
                    'crc', rom_string, is_header_detail=False, rom_attrs=True, hash_length=8
                )
                rom_string = re.sub(f'crc {rom_crc}', '', rom_string)

                rom_md5 = get_detail(
                    'md5', rom_string, is_header_detail=False, rom_attrs=True, hash_length=32
                )
                rom_string = re.sub(f'md5 {rom_md5}', '', rom_string)

                rom_sha1 = get_detail(
                    'sha1', rom_string, is_header_detail=False, rom_attrs=True, hash_length=40
                )
                rom_string = re.sub(f'sha1 {rom_sha1}', '', rom_string)

                rom_sha256 = get_detail(
                    'sha256', rom_string, is_header_detail=False, rom_attrs=True, hash_length=64
                )
                rom_string = re.sub(f'sha256 {rom_sha256}', '', rom_string)

                # Check that name is defined
                if not get_detail('name', rom_string, is_header_detail=False, rom_attrs=False):
                    skip_node = True
                    break
                else:
                    rom_list.append(
                        f'\t\t<rom name="{get_detail("name", rom_string, is_header_detail=False, rom_attrs=False)}"'
                    )

                # Check that there's at least one hash
                if not rom_crc and not rom_md5 and not rom_sha1 and not rom_sha256:
                    skip_node = True
                    break

                if not rom_size:
                    rom_size = "0"

                if rom_size:
                    rom_list.append(f' size="{rom_size}"')
                if rom_crc:
                    rom_list.append(f' crc="{rom_crc}"')
                if rom_md5:
                    rom_list.append(f' md5="{rom_md5}"')
                if rom_sha1:
                    rom_list.append(f' sha1="{rom_sha1}"')
                if rom_sha256:
                    rom_list.append(f' sha256="{rom_sha256}"')
                rom_list.append('/>\n')

            # Skip titles with no size or hashes
            if skip_node:
                continue

            # Build the game entry
            convert_dat.append(
                f'\t<game name="{get_detail("name", title, is_header_detail=False)}">\n'
            )

            if dat_category != '':
                convert_dat.append(f'\t\t<category>{dat_category}</category>\n')

            if not get_detail('description', title, is_header_detail=False):
                convert_dat.append(
                    f'\t\t<description>{get_detail("name", title, is_header_detail=False)}</description>\n'
                )
            else:
                convert_dat.append(
                    f'\t\t<description>{get_detail("description", title, is_header_detail=False)}</description>\n'
                )

            convert_dat.append(''.join(rom_list))
            convert_dat.append('\t</game>\n')

        convert_dat.append('</datafile>')
    else:
        eprint(
            f'• {Font.b}Error{Font.be}: file isn\'t a Logiqx XML or CLRMAMEPro DAT file.',
            level='error',
        )
        if input_type == 'file':
            if gui_input:
                raise ExitRetool
            else:
                sys.exit(1)
        else:
            input_dat.end = True
            return input_dat

    return Dat(convert_dat, [], dat_name, dat_description, dat_version, dat_author, dat_url)


def format_system_name(
    original_name: str,
    config: Config,
    url: str = '',
    homepage: str = '',
    comment: str = '',
    author: str = '',
) -> str:
    """
    Sanitizes the system name to match it with clone lists, metadata files, and system configs.

    Args:
        original_name (str): The original system name to process.

        config (Config): The Retool config object.

        url (str, optional): The URL in the header of the input DAT. Defaults to `''`.

        homepage (str, optional): The homepage in the header of the input DAT. Defaults
        to `''`.

        comment (str, optional): The comment in the header of the input DAT. Defaults to
        `''`.

        author (str, optional): The author in the header of the input DAT. Defaults to
        `''`.

    Returns:
        str: The formatted system name.
    """
    remove_string: str = f' \\(({"|".join(config.dat_file_tags)})\\)'

    search_name: str = ''

    if re.search(remove_string, original_name) is not None:
        search_name = re.sub(remove_string, '', original_name)
    else:
        search_name = original_name

    # Add group names to differentiate DATs that cover the same system
    if 'no-intro' in url:
        search_name = f'{search_name} (No-Intro)'
    elif 'MAMERedump' in url or 'MAME Redump' in author:
        search_name = f'{search_name} (MAME Redump)'
    elif (
        'redump' in url
        or 'Redump.org ISOs converted' in comment
        or 'Redump' in author
        or 'redump' in author
    ):
        search_name = f'{search_name} (Redump)'
    elif 'TOSEC' in homepage or 'tosecdev.org' in url:
        search_name = f'{search_name} (TOSEC)'
    else:
        search_name = f'{search_name}'

    # Deal with https://dats.site DATs
    if 'GameCube' in search_name:
        if (
            'NKit GCZ' in search_name
            or 'NKit ISO' in search_name
            or 'NKit RVZ' in search_name
            or 'NASOS' in search_name
        ):
            search_name = 'Nintendo - GameCube (Redump)'

    if 'Wii' in search_name:
        if (
            'NKit GCZ' in search_name
            or 'NKit ISO' in search_name
            or 'NKit RVZ' in search_name
            or 'NASOS' in search_name
        ):
            search_name = 'Nintendo - Wii (Redump)'

    if 'Wii U' in search_name and 'WUX' in search_name:
        search_name = 'Nintendo - Wii U (Redump)'

    return search_name


def process_dat(dat_file: str, input_type: str, gui_input: UserInput | None, config: Config) -> Dat:
    """
    Reads in an input DAT file and prepares the data for use in Retool. Also imports
    system configs, including the related clone list and metadata file.

    Args:
        dat_file (str): The DAT file being processed.

        input_type (str): Whether Retool is operating on a file or folder.

        gui_input (UserInput): Used to determine whether or not the function is being
        called from the GUI.

        config (Config): The Retool config object.

    Raises:
        ExitRetool: Silently exit if run from the GUI, so UI elements can
        re-enable.

    Returns:
        Dat: A Dat object created from the input DAT, so Retool can work on the
        data efficiently.
    """
    # Set a string for skipping to the next file if something goes wrong in a batch
    # operation
    if input_type != 'file':
        next_status: str = ' Skipping file...'
    else:
        next_status = ''

    # Import the DAT file
    eprint(f'• Reading DAT file: "{Font.b}{pathlib.Path(dat_file).resolve()}{Font.be}"')

    input_dat: Dat = Dat()

    try:
        with open(pathlib.Path(dat_file), encoding='utf-8') as input_file:
            eprint('• Validating DAT file... ')
            input_dat.contents = input_file.readlines()
            input_dat.contents_str = ''.join(input_dat.contents)

    except OSError as e:
        eprint(f'• {Font.b}Error{Font.be}: {e!s}.{next_status}', level='error')
        if input_type == 'file':
            raise
        else:
            input_dat.end = True
            return input_dat

    # Check the DAT file format -- if it's CLRMAMEPro format, convert it to LogiqX
    if 'clrmamepro' in input_dat.contents[0]:
        if not gui_input:
            eprint('• Validating DAT file... file is a CLRMAMEPro DAT file.', overwrite=True)
            eprint('• Converting DAT file to Logiqx XML... ')
        input_dat = convert_clrmame_dat(input_dat, input_type, gui_input, config)

        # Go to the next file in a batch operation if something went wrong.
        if input_dat.end:
            return input_dat

    # Exit if there are entity or element tags to avoid abuse
    abuse_tags: list[str] = ['<!ENTITY', '<!ELEMENT']
    for abuse_tag in abuse_tags:
        if list(filter(lambda x: abuse_tag in x, input_dat.contents)):
            eprint('• Validating DAT file... failed.', overwrite=True)
            eprint(
                f'• {Font.b}Error{Font.be}: Entity and element tags aren\'t '
                f'supported in DAT files. Exiting...{next_status}',
                level='error',
            )
            if gui_input:
                raise ExitRetool
            else:
                sys.exit(1)

    # Get the original header
    header_found: bool = False
    input_dat.original_header = []

    for line in input_dat.contents:
        if '<header>' in line:
            header_found = True

        if '</header>' in line:
            break

        if header_found and '<header>' not in line:
            input_dat.original_header.append(line)

    input_dat.original_header.append(
        f'\t\t<retool>Created by Retool {const.__version__}</retool>\n'
    )

    # Check for a valid LogiqX dat
    validation_tags: list[str] = ['<datafile', '<?xml', '<game', '<header']
    validation_bool: list[bool] = [False, False, False, False]

    for i, validation_tag in enumerate(validation_tags):
        validation_bool[i] = bool(list(filter(lambda x: validation_tag in x, input_dat.contents)))
        continue

    if not all(validation_bool):
        validation_tags = ['<datafile', '<?xml', '<machine', '<header']
        validation_bool = [False, False, False, False]

        for i, validation_tag in enumerate(validation_tags):
            validation_bool[i] = bool(
                list(filter(lambda x: validation_tag in x, input_dat.contents))
            )
            continue

    if all(validation_bool):
        # Fix any content that might causes Logiqx DTD check failures
        try:
            for i, line in enumerate(input_dat.contents):
                # Edit any unexpected XML declarations
                regex_search = re.search('<\\?xml.*?>', input_dat.contents[0])
                regex_search_str: str = ''

                if regex_search:
                    regex_search_str = regex_search.group()

                if re.search('<\\?xml.*?>', line):
                    input_dat.contents[i] = input_dat.contents[i].replace(
                        regex_search_str, '<?xml version="1.0"?>'
                    )
                    input_dat.contents_str = ''.join(input_dat.contents)

                # Check if the LogiqX DTD is present
                if '<!DOCTYPE datafile PUBLIC "-//Logiqx//DTD ROM Management Datafile//EN"' in line:
                    input_dat.is_dtd = True

                # Grab <datafile> tag in case an XSD reference is present
                if '<datafile' in line:
                    input_dat.datafile_tag = line.strip()

                # Capture, then remove CLRMAMEPro and Romcenter declarations
                if re.search('.*?<(clrmamepro|romcenter).*?>', line):
                    input_dat.dat_manager_directives.append(input_dat.contents[i])
                    input_dat.contents[i] = ''
                    input_dat.contents_str = ''.join(input_dat.contents)
                if re.search('.*?</header>', line):
                    break
        except Exception:
            eprint('• Validating DAT file... failed.', overwrite=True)
            eprint(
                f'• {Font.b}Error{Font.be}: File is missing an XML '
                f'declaration. It\'s probably not a DAT file.'
                f'{next_status}',
                level='error',
            )
            if input_type == 'file':
                if gui_input:
                    raise ExitRetool
                else:
                    sys.exit(1)
            else:
                input_dat.end = True
                return input_dat

        # Parse the DAT
        parser = etree.XMLParser(
            encoding='utf-8',
            recover=True,
            ns_clean=True,
            remove_pis=True,
            resolve_entities=False,
            strip_cdata=True,
            remove_comments=True,
        )
        root = etree.XML(html_.tostring(html_.fromstring(input_dat.contents_str)), parser=parser)

        # Validate against the Logiqx DTD
        if input_dat.is_dtd:
            try:
                with open(pathlib.Path(config.retool_location).joinpath('datafile.dtd')) as dtdfile:
                    dtd: etree.DTD = etree.DTD(dtdfile)
                    failed_check: bool = False

                    try:
                        if not config.user_input.no_dtd:
                            if not dtd.validate(root):
                                eprint('• Validating DAT file... failed.', overwrite=True)
                                eprint(
                                    f'• {Font.b}Warning{Font.be}: DAT file doesn\'t '
                                    'comply with the Logiqx DTD standard. This might have unexpected results.',
                                    level='warning',
                                )
                                eprint(
                                    f'  DTD violation: {dtd.error_log.last_error}.'  # type: ignore
                                    f'{next_status}',
                                    level='warning',
                                )
                                eprint('')
                                if input_type == 'file':
                                    failed_check = True
                                else:
                                    input_dat.end = True
                                    return input_dat
                    except etree.XMLSyntaxError as e:
                        eprint('• Validating DAT file... failed.', overwrite=True)
                        eprint(
                            f'• {Font.b}Error{Font.be}: DAT file is malformed. '
                            f'{e}.{next_status}',
                            level='error',
                        )
                        if input_type == 'file':
                            if gui_input:
                                raise ExitRetool
                            else:
                                sys.exit(1)
                        else:
                            input_dat.end = True
                            return input_dat
                    else:
                        if not failed_check:
                            eprint(
                                '• Validating DAT file... file is a Logiqx DAT file.',
                                overwrite=True,
                            )

            except OSError as e:
                eprint(f'• {Font.b}Error{Font.be}: {e!s}{next_status}', level='error')
                if input_type == 'file':
                    raise
                else:
                    input_dat.end = True
                    return input_dat
        else:
            eprint('• Validating DAT file... done.', overwrite=True)

        # Clear out attributes to save memory
        input_dat.contents.clear()
        input_dat.contents_str = ''

        # Get header details
        def header_details(key: str) -> None:
            """
            Gets the header details from the input DAT.

            Args:
                key (str): The header detail to extract.
            """
            for header in root.findall('header'):
                for detail in header:
                    if detail.tag == key:
                        if not detail.text:
                            setattr(input_dat, key, 'Unknown')
                        else:
                            setattr(input_dat, key, detail.text)

        header_details('name')
        header_details('description')
        header_details('version')
        header_details('author')
        header_details('homepage')
        header_details('url')
        header_details('comment')
        header_details('retool')

        # Fix some formatting
        input_dat.name = re.sub(' \\(Retool.*?\\)', '', input_dat.name).replace('&amp;', '&')

        # Sanitize some header details which are used in the output filename
        input_dat.name = TitleTools.replace_invalid_characters(
            input_dat.name, config, is_header_detail=True
        )
        input_dat.version = TitleTools.replace_invalid_characters(
            input_dat.version, config, is_header_detail=True
        )

        for filename in config.reserved_filenames:
            search_string: str = f'^{filename}$'
            if re.search(search_string, input_dat.name) is not None:
                input_dat.name = 'Unknown'
            if re.search(search_string, input_dat.version) is not None:
                input_dat.version = 'Unknown'

        # Sanitize the system name to make referencing support files like clone lists and
        # system configurations easier
        input_dat.search_name = format_system_name(
            input_dat.name,
            config,
            input_dat.url,
            input_dat.homepage,
            input_dat.comment,
            input_dat.author,
        )

        # Import system settings
        from modules.input import import_clone_list, import_metadata, import_system_settings

        import_system_settings(
            config,
            input_dat.search_name,
            const.SYSTEM_LANGUAGE_ORDER_KEY,
            const.SYSTEM_REGION_ORDER_KEY,
            const.SYSTEM_LOCALIZATION_ORDER_KEY,
            const.SYSTEM_VIDEO_ORDER_KEY,
            const.SYSTEM_LIST_PREFIX_KEY,
            const.SYSTEM_LIST_SUFFIX_KEY,
            const.SYSTEM_OVERRIDE_EXCLUDE_KEY,
            const.SYSTEM_OVERRIDE_INCLUDE_KEY,
            const.SYSTEM_FILTER_KEY,
            const.SYSTEM_EXCLUSIONS_OPTIONS_KEY,
        )

        # If the DAT file has already been processed, exit
        if input_dat.retool and not config.user_input.reprocess_dat:
            eprint(
                '• Skipping file as it\'s already been processed by Retool. You can allow this with\n'
                f'  the {Font.b}--reprocess{Font.be} flag, or by setting the appropriate output option in Retool GUI.'
            )
            if input_type == 'file':
                if gui_input:
                    raise ExitRetool
                else:
                    sys.exit(0)
            else:
                input_dat.end = True
                return input_dat

        # Provide DAT details to the user to reassure them the correct file is being processed
        eprint(f'\n│  {Font.b}DAT DETAILS{Font.be}')
        eprint(f'│  Description: {input_dat.description}', indent=3)
        eprint(f'│  Author/s: {input_dat.author}', indent=3)
        eprint(f'│  URL: {input_dat.url}', indent=3)
        eprint(f'│  Version: {input_dat.version}', indent=3)

        # Check if the DAT is numbered
        if 'no-intro' in input_dat.url.lower():
            input_dat.numbered = True

            for game in root.findall('game'):
                if not re.search('^([0-9]|x|z)([0-9]|B)[0-9]{2,2} - ', game.attrib['name']):  # type: ignore
                    input_dat.numbered = False

            for machine in root.findall('machine'):
                if not re.search('^([0-9]|x|z)([0-9]|B)[0-9]{2,2} - ', machine.attrib['name']):  # type: ignore
                    input_dat.numbered = False

            numbered_dat: str = ['No', 'Yes'][input_dat.numbered]
            eprint(f'│  Numbered dat: {numbered_dat}', indent=3)
        eprint('')

        search_games: list[Any] = root.findall('game')

        if not search_games:
            search_games = root.findall('machine')

        if config.user_input.trace or config.user_input.single_cpu:
            alive_bar_context = nullcontext()
            eprint('• Processing DAT file...')
        else:
            progress_bar: str = 'smooth'
            spinner: str = 'waves'
            parent_processes: list[str] = [
                str(x).lower() for x in psutil.Process(os.getpid()).parents()
            ]

            if any(
                s
                for s in parent_processes
                if 'cmd.exe' in s or 'powershell.exe' in s or 'explorer.exe' in s
            ):
                if not any(
                    s for s in parent_processes if 'code.exe' in s or 'windowsterminal.exe' in s
                ):
                    progress_bar = 'classic2'
                    spinner = 'classic'

            alive_bar_context = alive_bar(
                2 + len(search_games),
                title='• Processing DAT file',
                length=20,
                enrich_print=False,
                stats=False,
                monitor='{percent:.2%}',
                receipt_text=True,
                bar=progress_bar,
                spinner=spinner,
                file=sys.stderr,
            )

        with alive_bar_context as bar:
            # Create an object for each title
            all_games: list[Any] = []

            for game in search_games:
                # Get data out of the lxml element so it can be multiprocessed
                node_dict: dict[str, Any] = {'name': game.attrib['name']}
                roms: list[dict[str, str]] = []
                categories: list[str] = []

                # Grab other data from the element, like descriptions
                [node_dict.update({d.tag: d.text}) for d in list(game)]

                node_dict['element_name'] = game.tag

                # Get multiple categories if the input DAT supports them
                for category in game.xpath('category'):  # type: ignore
                    categories.append(str(category.text))  # type: ignore

                if categories:
                    node_dict['category'] = categories
                else:
                    node_dict['category'] = []

                # Get the rom node attributes
                rom_dict: dict[str, str] = {}

                for rom in game.xpath('rom'):  # type: ignore
                    rom_dict = dict(rom.attrib)  # type: ignore
                    rom_dict['type'] = 'rom'
                    roms.append(rom_dict)

                for rom in game.xpath('disk'):  # type: ignore
                    rom_dict = dict(rom.attrib)  # type: ignore
                    rom_dict['type'] = 'disk'
                    roms.append(rom_dict)

                # Check for at least a size or one hash in the rom node
                skip_node: bool = False

                if not (
                    'size' in rom.attrib  # type: ignore
                    or 'crc' in rom.attrib  # type: ignore
                    or 'md5' in rom.attrib  # type: ignore
                    or 'sha1' in rom.attrib  # type: ignore
                    or 'sha256' in rom.attrib  # type: ignore
                ):
                    if not config.user_input.empty_titles:
                        skip_node = True
                        break

                if skip_node:
                    continue

                node_dict['roms'] = roms

                all_games.append(node_dict)

                if not (config.user_input.trace or config.user_input.single_cpu):
                    bar()  # type: ignore

            if not all_games:
                eprint(
                    f'\n• {Font.b}Error{Font.be}: {Font.b}"{dat_file}"{Font.be}. No valid '
                    f'titles in input DAT file. Titles must have at least a size or '
                    f'one hash.{next_status}',
                    level='error',
                )

                if input_type == 'file':
                    if gui_input:
                        raise ExitRetool
                    else:
                        sys.exit(1)
                else:
                    input_dat.end = True
                    return input_dat

            # Check all the overrides and post filters for invalid regex and strip it out
            if not config.user_input.no_overrides:
                config.global_exclude = regex_test(
                    list(config.global_exclude), 'global exclude', 'user filter'
                )
                config.global_include = regex_test(
                    list(config.global_include), 'global include', 'user filter'
                )
                config.system_exclude = regex_test(
                    list(config.system_exclude), 'system exclude', 'user filter'
                )
                config.system_include = regex_test(
                    list(config.system_include), 'system include', 'user filter'
                )

            if config.global_filter:
                config.global_filter = regex_test(
                    list(config.global_filter), 'global post filter', 'user filter'
                )

            if config.system_filter:
                override_status: list[str | dict[str, str]] = [
                    x
                    for x in config.system_filter
                    if x == {'override': 'true'} or x == {'override': 'false'}
                ]
                regex_test_system_filter: list[str] = regex_test(
                    [
                        str(x)
                        for x in config.system_filter
                        if x != {'override': 'true'} and x != {'override': 'false'}
                    ],
                    'system post filter',
                    'user filter',
                )

                config.system_filter = override_status

                for regex in regex_test_system_filter:
                    config.system_filter.append(regex)

            # Import the clone list
            input_dat.clone_list = import_clone_list(input_dat, gui_input, config, bar)

            # Import the metadata file
            input_dat.metadata = import_metadata(input_dat, config)

            if not (config.user_input.trace or config.user_input.single_cpu):
                bar()  # type: ignore

            # Define DatNode as the function to run on multiple processors, and
            # use a partial to prepush arg values into it as a sort of
            # prepackaged function so we can use it in a map later
            func = partial(DatNode, config, input_dat)

            # Multiprocessing to speed up DatNode creation
            if config.user_input.single_cpu:
                process_list = list(map(func, all_games))
            else:
                with InterruptiblePool(int(str(os.cpu_count()))) as p:
                    process_list = p.map(func, all_games)

            if not (config.user_input.trace or config.user_input.single_cpu):
                bar()  # type: ignore

            # Create a dictionary of titles sorted by group name
            original_titles: dict[str, set[DatNode]] = {}

            duplicate_titles: set[DatNode] = set()
            duplicate_names: set[str] = set()

            for title in process_list:
                if title.group_name not in original_titles:
                    original_titles[title.group_name] = set()

                # Check there isn't a duplicate title or name in the group, as No-Intro
                # doesn't check for these things
                for original_title in original_titles[title.group_name]:
                    if original_title.full_name == title.full_name:
                        # Check first if the entire title is duplicated, use the <rom>
                        # node a proxy
                        if original_title.roms == title.roms:
                            duplicate_titles.add(title)
                            continue

                        # Rename files with the same filename. First, get the current dupe number.
                        dupe_number: int = 0

                        if re.search(' \\(Dupe \\d+\\)', title.full_name):
                            dupe_string: str = pattern2string(
                                re.compile(' \\(Dupe \\d+\\)'), title.full_name
                            )
                            dupe_number = int(pattern2string(re.compile('\\d+'), dupe_string)) + 1
                            title.full_name = re.sub(' \\(Dupe \\d+\\)', '', title.full_name)
                            title.description = re.sub(' \\(Dupe \\d+\\)', '', title.description)
                            title.short_name = re.sub(' \\(Dupe \\d+\\)', '', title.short_name)
                            title.region_free_name = re.sub(
                                ' \\(Dupe \\d+\\)', '', title.region_free_name
                            )
                        else:
                            dupe_number += 1

                        before_rename: str = title.full_name
                        title.full_name = f'{title.full_name} (Dupe {dupe_number})'
                        title.description = f'{title.description} (Dupe {dupe_number})'
                        title.short_name = f'{title.short_name} (Dupe {dupe_number})'
                        title.region_free_name = f'{title.region_free_name} (Dupe {dupe_number})'

                        if f'{before_rename} > {title.full_name}' not in duplicate_names:
                            duplicate_names.add(
                                f'{Font.warning_bold}{before_rename}{Font.warning} -> {Font.warning_bold}{title.full_name}{Font.warning}'
                            )

                original_titles[title.group_name].add(title)

            # Remove duplicate titles
            for title in duplicate_titles:
                if title in process_list:
                    config.stats.duplicate_titles_count += 1
                    process_list.remove(title)
                if title in original_titles[title.group_name]:
                    original_titles[title.group_name].remove(title)

            input_dat.contents_dict = original_titles

            if not (config.user_input.trace or config.user_input.single_cpu):
                bar()  # type: ignore

            if duplicate_names:
                eprint(
                    '• The following titles with identical names were found in '
                    'the input DAT file, and will be renamed. They won\'t be processed as clones:\n',
                    level='warning',
                )

                for duplicate_title in sorted(duplicate_names):
                    eprint(f'  •  {duplicate_title}', level='warning', wrap=False)

                eprint(f'{Font.end}')

        eprint('• Processing DAT file... done.', overwrite=True)
    else:
        eprint('• Processing DAT file... failed.', overwrite=True)
        if '<game' not in input_dat.contents or '<machine' not in input_dat.contents:
            eprint(
                f'• {Font.b}"{dat_file}"{Font.be} is empty - no titles found.{next_status}',
                level='error',
            )
        else:
            eprint(
                f'• {Font.b}"{dat_file}"{Font.be} isn\'t a compatible DAT file.{next_status}',
                level='error',
            )

        if input_type == 'file':
            if gui_input:
                raise ExitRetool
            else:
                sys.exit(1)
        else:
            input_dat.end = True
            return input_dat

    return input_dat
